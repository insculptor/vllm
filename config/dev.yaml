dirs:
  ROOT_PATH: "/mnt/c/Users/erdrr/OneDrive/Desktop/KB/Projects/vllm"
  MODELS_BASE_DIR: "/mnt/c/Users/erdrr/OneDrive/Desktop/KB/Projects/vllm/models"
  CACHE_DIR: "/mnt/c/Users/erdrr/OneDrive/Desktop/KB/Projects/vllm/cache"

models:
  CAUSAL_MODEL: "google/gemma-2-2b"


sampling_parameters:
  temperature: 0.8
  top_p: 0.95
  max_tokens: 100

engine_args:
  model: "/mnt/c/Users/erdrr/OneDrive/Desktop/KB/Projects/MODELS/google/gemma-2-2b"
  download_dir: "/mnt/c/Users/erdrr/OneDrive/Desktop/KB/Projects/vllm/models"
  load_format: "safetensors"
  tensor_parallel_size: 1
  max_num_batched_tokens: 4096
  dtype: "float16"
  seed: 42
  gpu_memory_utilization: 0.9
  max_model_len: 2672  # Adjust as needed
  swap_space: 4  # GB


server:
  host: "0.0.0.0"
  port: 8000
  timeout_keep_alive: 5  # seconds

logger:
  level: "DEBUG"
  file: "/mnt/c/Users/erdrr/OneDrive/Desktop/KB/Projects/vllm/logs/vllm_server.log"
